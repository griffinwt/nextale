{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "#https://stackoverflow.com/questions/21402485/pandas-how-to-filter-a-df-to-get-unique-entries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances, cosine_distances, cosine_similarity\n",
    "from scipy import sparse\n",
    "from matplotlib import pyplot as plt\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_search(category, query, wout='no'):\n",
    "\n",
    "    if category.lower() == 'video games':\n",
    "        lookup, recommender = pd.read_pickle('./pickles/videog_look.pkl'),pd.read_pickle('./pickles/videog_rec.pkl')\n",
    "    elif category.lower() == 'movies':\n",
    "        lookup, recommender = pd.read_pickle('./pickles/movies_look.pkl'), pd.read_pickle('./pickles/movie_rec.pkl') \n",
    "    elif category.lower() == 'books':\n",
    "        lookup, recommender = pd.read_pickle('./pickles/books_look.pkl'), pd.read_pickle('./pickles/books_rec.pkl')\n",
    "    else:\n",
    "        return \"Sorry, that wasn't one of the available categories\"\n",
    "\n",
    "    try:\n",
    "        #query=query.title() #uppercase first letter of each word in the query in case it's not entered that way\n",
    "        query=query.lower() #lowercase\n",
    "        titles = list(lookup[lookup['product_title'].str.contains(query)]['product_title'])\n",
    "        q = titles[0] #this is the item to search for\n",
    "\n",
    "        if wout.lower() == 'no':\n",
    "            query_dict = dict(recommender.loc[q].sort_values())\n",
    "            \n",
    "            final_printout = ''\n",
    "            for key in list(query_dict.keys())[1:11]:\n",
    "                final_printout += '\\n' #add new line\n",
    "                final_printout += f'{key}' #print item name\n",
    "                final_printout += '\\n'\n",
    "                final_printout += f\"\"\"\n",
    "                This item has {round(lookup[lookup['product_title']==key]['tot_prod_reviews'].mean())} reviews \n",
    "                and a {round(lookup[lookup['product_title']==key]['avg_prod_stars'].mean(), 2)} average star rating\"\"\"\n",
    "                final_printout += '\\n'\n",
    "\n",
    "            return print(f'''\n",
    "\n",
    "            Recommending items similar to: {q}\n",
    "            This item has {round(lookup[lookup['product_title']==q]['tot_prod_reviews'].mean())} reviews\n",
    "            and a {round(lookup[lookup['product_title']==q]['avg_prod_stars'].mean(), 2)} average star rating.\n",
    "\n",
    "            Here are the 10 recommended items for you based on your search parameters:\n",
    "            \n",
    "            {final_printout}\n",
    "            \n",
    "            ''')\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            wout = wout.title() #capitlize first letters\n",
    "            query_dict = dict(recommender.loc[q].sort_values())\n",
    "            filtered_query = [] #make empty list\n",
    "            for key, value in query_dict.items(): #index into dictionary of results\n",
    "                if wout not in key: #check if avoided keyword is in results\n",
    "                    filtered_query.append((key, value)) #make list of results that DON'T include \"wout\" keyword\n",
    "            \n",
    "            final_printout = ''\n",
    "            for item in filtered_query[1:11]:\n",
    "                final_printout += '\\n' #add new line\n",
    "                final_printout += f'{item[0]}' #print item name\n",
    "                final_printout += '\\n'\n",
    "                final_printout += f\"\"\"\n",
    "                This item has {round(lookup[lookup['product_title']==item[0]]['tot_prod_reviews'].mean())} reviews \n",
    "                and a {round(lookup[lookup['product_title']==item[0]]['avg_prod_stars'].mean(), 2)} average star rating\"\"\"\n",
    "                final_printout += '\\n'\n",
    "            return print(f'''\n",
    "\n",
    "            Recommending items similar to: {q}\n",
    "            This item has {round(lookup[lookup['product_title']==q]['tot_prod_reviews'].mean())} reviews\n",
    "            and a {round(lookup[lookup['product_title']==q]['avg_prod_stars'].mean(), 2)} average star rating.\n",
    "\n",
    "            Here are the 10 recommended items for you based on your search EXCLUDING \"{wout}\":\n",
    "            \n",
    "            {final_printout}\n",
    "            \n",
    "            ''')\n",
    "        \n",
    "    except:\n",
    "        return print(f'Sorry, \"{query}\" does not appear to be in the product database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, \"batman\" does not appear to be in the product database\n"
     ]
    }
   ],
   "source": [
    "rec_search('books', 'batman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay - this works and I got it running my flask app! What if, however, I return my output as a DATAFRAME instead of a long text segment? I think the table-ish formatting might look better and be easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in pickled dataframes\n",
    "books_df, books_rec, movies_df, movies_rec, vg_df, vg_rec = pd.read_pickle('./pickles/books_look.pkl'), pd.read_pickle('./pickles/books_rec.pkl'), pd.read_pickle('./pickles/movies_look.pkl'), pd.read_pickle('./pickles/movie_rec.pkl'), pd.read_pickle('./pickles/videog_look.pkl'), pd.read_pickle('./pickles/videog_rec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_search(category, query, wout='no'):\n",
    "\n",
    "    if category.lower() == 'video games':\n",
    "        lookup, recommender = vg_df, vg_rec #pd.read_pickle('./pickles/videog_look.pkl'),pd.read_pickle('./pickles/videog_rec.pkl')\n",
    "    elif category.lower() == 'movies':\n",
    "        lookup, recommender = movies_df, movies_rec #pd.read_pickle('./pickles/movies_look.pkl'), pd.read_pickle('./pickles/movie_rec.pkl') \n",
    "    elif category.lower() == 'books':\n",
    "        lookup, recommender = books_df, books_rec #pd.read_pickle('./pickles/books_look.pkl'), pd.read_pickle('./pickles/books_rec.pkl')\n",
    "    else:\n",
    "        return \"Sorry, that wasn't one of the available categories\"\n",
    "\n",
    "    try:\n",
    "        query=query.title() #uppercase first letter of each word in the query in case it's not entered that way\n",
    "        titles = list(lookup[lookup['product_title'].str.contains(query)]['product_title'])\n",
    "        q = titles[0] #this is the item to search for\n",
    "\n",
    "        if wout.lower() == 'no':\n",
    "            query_dict = dict(recommender.loc[q].sort_values())\n",
    "            \n",
    "            top10_prods = []\n",
    "            num_prod_revs = []\n",
    "            avg_prod_stars = []\n",
    "            for key in list(query_dict.keys())[1:11]:\n",
    "                top10_prods.append(key)\n",
    "                num_prod_revs.append(round(lookup[lookup['product_title']==key]['tot_prod_reviews'].mean()))\n",
    "                avg_prod_stars.append(round(lookup[lookup['product_title']==key]['avg_prod_stars'].mean(), 2))\n",
    "            #print(top10_prods, num_prod_revs, avg_prod_stars)\n",
    "            final_output_df = pd.DataFrame(data = {\n",
    "                'Recommended Items':top10_prods,\n",
    "                'Total Reviews for Product':num_prod_revs,\n",
    "                'Avg Product Star Rating(1-5)':avg_prod_stars\n",
    "            }, index=range(1,11))\n",
    "\n",
    "            return final_output_df            \n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            wout = wout.title() #capitlize first letters\n",
    "            query_dict = dict(recommender.loc[q].sort_values())\n",
    "            filtered_query = [] #make empty list\n",
    "            for key, value in query_dict.items(): #index into dictionary of results\n",
    "                if wout not in key: #check if avoided keyword is in results\n",
    "                    filtered_query.append((key, value)) #make list of results that DON'T include \"wout\" keyword\n",
    "            \n",
    "            top10_prods = []\n",
    "            num_prod_revs = []\n",
    "            avg_prod_stars = []\n",
    "            for item in filtered_query[1:11]:\n",
    "                top10_prods.append(item[0])\n",
    "                num_prod_revs.append(round(lookup[lookup['product_title']==item[0]]['tot_prod_reviews'].mean()))\n",
    "                avg_prod_stars.append(round(lookup[lookup['product_title']==item[0]]['avg_prod_stars'].mean(), 2))\n",
    "            \n",
    "                \n",
    "            final_output_df = pd.DataFrame(data = {\n",
    "                'Recommended Items':top10_prods,\n",
    "                'Total Reviews for Product':num_prod_revs,\n",
    "                'Avg Product Star Rating(1-5)':avg_prod_stars\n",
    "                }, index=range(1,11))\n",
    "                \n",
    "                \n",
    "                \n",
    "            return final_output_df\n",
    "        \n",
    "    except:\n",
    "        return f'Sorry, \"{query}\" does not appear to be in the product database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommended Items</th>\n",
       "      <th>Total Reviews for Product</th>\n",
       "      <th>Avg Product Star Rating(1-5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V for Vendetta</td>\n",
       "      <td>92</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daredevil Visionaries - Frank Miller, Vol. 1</td>\n",
       "      <td>18</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marvels</td>\n",
       "      <td>31</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frank Miller's Ronin</td>\n",
       "      <td>24</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Infinity Gauntlet TPB</td>\n",
       "      <td>12</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New X-Men Vol. 1: E is for Extinction (v. 1)</td>\n",
       "      <td>27</td>\n",
       "      <td>4.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kingdom Come</td>\n",
       "      <td>134</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Marvel 1602 HC (Marvel Heroes)</td>\n",
       "      <td>16</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Preacher VOL 06: War in the Sun (Preacher (DC Comics))</td>\n",
       "      <td>15</td>\n",
       "      <td>4.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6: Sandman, The: Fables &amp; Reflections - Book VI</td>\n",
       "      <td>19</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Recommended Items  \\\n",
       "1                                           V for Vendetta   \n",
       "2             Daredevil Visionaries - Frank Miller, Vol. 1   \n",
       "3                                                  Marvels   \n",
       "4                                     Frank Miller's Ronin   \n",
       "5                                    Infinity Gauntlet TPB   \n",
       "6             New X-Men Vol. 1: E is for Extinction (v. 1)   \n",
       "7                                             Kingdom Come   \n",
       "8                           Marvel 1602 HC (Marvel Heroes)   \n",
       "9   Preacher VOL 06: War in the Sun (Preacher (DC Comics))   \n",
       "10         6: Sandman, The: Fables & Reflections - Book VI   \n",
       "\n",
       "    Total Reviews for Product  Avg Product Star Rating(1-5)  \n",
       "1                          92                          4.54  \n",
       "2                          18                          4.28  \n",
       "3                          31                          4.48  \n",
       "4                          24                          4.38  \n",
       "5                          12                          4.58  \n",
       "6                          27                          4.26  \n",
       "7                         134                          4.37  \n",
       "8                          16                          4.25  \n",
       "9                          15                          4.93  \n",
       "10                         19                          4.32  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_search('books', 'batman', 'batman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that'll do for a dataframe return item. I'm not convinced that will be the best return option but it's good to have the capability.\n",
    "\n",
    "I've noticed my function is running slower than I'd like in app format (streamlit or flask). I want to find ways to trim the amount of work it's doing. I think I can cut some unused columns from the \"lookup\" dataframes. I can also potentially drop all but a single row for each product, since each row contains the aggregate information (tot_prod_reviews, avg_prod_stars) for each item. I'm not doing these calculations on the fly so I don't need to have all the contributing data, just a single representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup, recommender = pd.read_pickle('./pickles/videog_look.pkl'),pd.read_pickle('./pickles/videog_rec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1648136, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20952"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15938"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup['product_title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting that I have more unique product_id numbers than unique product_title(s). This indicates that some products were re-listed under different item numbers or possibly for sale under the same name by multiple sellers. I still think it makes sense to group these products together because, assuming reviews were based on the product not the seller, they will all reference the same item and ought to be grouped together. Indeed this is actually an advantage because anyone in the market for that product can see the aggregate of public opinion on the item rather than a fraction of it as represented only by buyers who purchased it from one unique seller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = lookup.groupby('product_title').first().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a filter of my video-game dataframe that only shows one row per item. We can see that no lookup information is lost because the total product reviews and average stars are still accounted for in their respective columns. If I use this dataframe to lookup queries and return search information, not only would it occupy a much smaller portion of memory (about 16,000 rows compared to 1.6 million!), it would also save some of the list indexing / combining that I'm forced to do in my lookup function to account for all the duplicates I was getting back.\n",
    "\n",
    "I can also drop customer_id, product_id, star_rating, and review_date because those do not apply to any returned values in my recommender function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup.reset_index(inplace=True) #add index, was removed during groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup.drop(columns=['customer_id', 'product_id', 'star_rating', 'review_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_title', 'tot_prod_reviews', 'avg_prod_stars'], dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup.sort_values(by='tot_prod_reviews', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                              $100,000 pyramid - pc\n",
       "1        (25) empty standard xbox 360 translucent green replacement games boxes / cases - vgbr14xbox\n",
       "2                      (25) standard black nintendo ds empty replacement game cases boxes vgbr14dsbk\n",
       "3                                          (4) wii fit balance board replacement foot leg extensions\n",
       "4          (5) empty standard xbox 360 translucent green replacement games boxes / cases #dvbr14xbox\n",
       "                                                    ...                                             \n",
       "15933                                                    udraw marvel super hero squad: comic combat\n",
       "15934                                                             udraw pictionary: ultimate edition\n",
       "15935                                                    udraw studio: instant artist - nintendo wii\n",
       "15936                     uxcell 3pcs replacement buttons conductive pads for nintendo nds lite ndsl\n",
       "15937                                       uxcell blue game card case for nintendo ds lite ndsi nds\n",
       "Name: product_title, Length: 15938, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup['product_title'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Batman Arkham Origins',\n",
       " 'Lego Batman 2 Super Hero',\n",
       " 'Batman Arkham City',\n",
       " 'Batman: Arkham City Game of the Year Edition',\n",
       " 'Lego Batman']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'batman'\n",
    "titles = list(lookup[lookup['product_title'].map(lambda x: x.lower()).str.contains(query)]['product_title'])\n",
    "titles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>product_title</th>\n",
       "      <th>tot_prod_reviews</th>\n",
       "      <th>avg_prod_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9891</td>\n",
       "      <td>PlayStation 4 500GB Console [Old Model]</td>\n",
       "      <td>10317</td>\n",
       "      <td>4.162256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4698</td>\n",
       "      <td>Grand Theft Auto V</td>\n",
       "      <td>8656</td>\n",
       "      <td>4.545055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1737</td>\n",
       "      <td>Call of Duty: Ghosts</td>\n",
       "      <td>7762</td>\n",
       "      <td>3.787426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123</td>\n",
       "      <td>Battlefield 4</td>\n",
       "      <td>4795</td>\n",
       "      <td>3.666945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>788</td>\n",
       "      <td>Assassin's Creed 4</td>\n",
       "      <td>4702</td>\n",
       "      <td>4.564866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15933</th>\n",
       "      <td>14210</td>\n",
       "      <td>Ultimate Civil War Battles: Robert E. Lee vs. Ulysses S. Grant - PC</td>\n",
       "      <td>11</td>\n",
       "      <td>1.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15934</th>\n",
       "      <td>3298</td>\n",
       "      <td>Duke Nukem: Critical Mass</td>\n",
       "      <td>11</td>\n",
       "      <td>3.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15935</th>\n",
       "      <td>3293</td>\n",
       "      <td>Duke Nukem</td>\n",
       "      <td>11</td>\n",
       "      <td>4.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15936</th>\n",
       "      <td>3284</td>\n",
       "      <td>DualPenSports - Nintendo 3DS</td>\n",
       "      <td>11</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15937</th>\n",
       "      <td>13335</td>\n",
       "      <td>The Lost Vikings</td>\n",
       "      <td>11</td>\n",
       "      <td>4.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15938 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  \\\n",
       "0       9891   \n",
       "1       4698   \n",
       "2       1737   \n",
       "3       1123   \n",
       "4        788   \n",
       "...      ...   \n",
       "15933  14210   \n",
       "15934   3298   \n",
       "15935   3293   \n",
       "15936   3284   \n",
       "15937  13335   \n",
       "\n",
       "                                                             product_title  \\\n",
       "0                                  PlayStation 4 500GB Console [Old Model]   \n",
       "1                                                       Grand Theft Auto V   \n",
       "2                                                     Call of Duty: Ghosts   \n",
       "3                                                            Battlefield 4   \n",
       "4                                                       Assassin's Creed 4   \n",
       "...                                                                    ...   \n",
       "15933  Ultimate Civil War Battles: Robert E. Lee vs. Ulysses S. Grant - PC   \n",
       "15934                                            Duke Nukem: Critical Mass   \n",
       "15935                                                           Duke Nukem   \n",
       "15936                                         DualPenSports - Nintendo 3DS   \n",
       "15937                                                     The Lost Vikings   \n",
       "\n",
       "       tot_prod_reviews  avg_prod_stars  \n",
       "0                 10317        4.162256  \n",
       "1                  8656        4.545055  \n",
       "2                  7762        3.787426  \n",
       "3                  4795        3.666945  \n",
       "4                  4702        4.564866  \n",
       "...                 ...             ...  \n",
       "15933                11        1.181818  \n",
       "15934                11        3.454545  \n",
       "15935                11        4.090909  \n",
       "15936                11        4.000000  \n",
       "15937                11        4.727273  \n",
       "\n",
       "[15938 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup.reset_index(inplace=True) #reest index to reflect order by total product reviews\n",
    "lookup.drop('index', inplace=True) #preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lookup.to_pickle('./pickles/vg_look_small.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's the new video game lookup saved! The size of the old pickled df was 94 MB and the new one is just 1 MB so I expect to see significant returns in terms of speed searching the new one for the recommender. Now, I want to to apply the same treatment to movies and books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_smaller_lookup(lookup_df):\n",
    "    print(lookup_df.shape) #preview initial shape\n",
    "    print(lookup_df['product_title'].nunique()) #unique product count\n",
    "    lookup_df = lookup_df.groupby('product_title').first().copy() #only 1 row for each unique product\n",
    "    lookup_df.reset_index(inplace=True) #add index, was removed during groupby\n",
    "    lookup_df.drop(columns=['customer_id', 'product_id', 'star_rating', 'review_date'], inplace=True) #drop unused columns\n",
    "    lookup_df.sort_values(by='tot_prod_reviews', ascending=False, inplace=True) #sort by most reviews\n",
    "    lookup_df.reset_index(inplace=True) #reset index\n",
    "    lookup_df.drop(columns=['index'], inplace=True) #drop original index (needed previously in order to sort)\n",
    "    return lookup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! I'll save this in my python file and call it in at the top of my next recommender notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup= pd.read_pickle('./pickles/movies_look.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4405432, 7)\n",
      "72385\n"
     ]
    }
   ],
   "source": [
    "movies_small = make_smaller_lookup(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>tot_prod_reviews</th>\n",
       "      <th>avg_prod_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Firefly: The Complete Series</td>\n",
       "      <td>4959</td>\n",
       "      <td>4.859649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jillian Michaels - 30 Day Shred</td>\n",
       "      <td>4958</td>\n",
       "      <td>4.547802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frozen</td>\n",
       "      <td>4569</td>\n",
       "      <td>4.688116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Frozen [Blu-ray]</td>\n",
       "      <td>4492</td>\n",
       "      <td>4.701915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mean Girls (Full Screen Edition)</td>\n",
       "      <td>4409</td>\n",
       "      <td>4.993876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72380</th>\n",
       "      <td>Repeat Performance</td>\n",
       "      <td>11</td>\n",
       "      <td>3.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72381</th>\n",
       "      <td>Repentance</td>\n",
       "      <td>11</td>\n",
       "      <td>4.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72382</th>\n",
       "      <td>Replicant [Blu-ray]</td>\n",
       "      <td>11</td>\n",
       "      <td>4.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72383</th>\n",
       "      <td>Glenn Gould: Hereafter</td>\n",
       "      <td>11</td>\n",
       "      <td>4.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72384</th>\n",
       "      <td>Zandalee</td>\n",
       "      <td>10</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72385 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          product_title  tot_prod_reviews  avg_prod_stars\n",
       "0          Firefly: The Complete Series              4959        4.859649\n",
       "1       Jillian Michaels - 30 Day Shred              4958        4.547802\n",
       "2                                Frozen              4569        4.688116\n",
       "3                      Frozen [Blu-ray]              4492        4.701915\n",
       "4      Mean Girls (Full Screen Edition)              4409        4.993876\n",
       "...                                 ...               ...             ...\n",
       "72380                Repeat Performance                11        3.363636\n",
       "72381                        Repentance                11        4.636364\n",
       "72382               Replicant [Blu-ray]                11        4.363636\n",
       "72383            Glenn Gould: Hereafter                11        4.272727\n",
       "72384                          Zandalee                10        3.600000\n",
       "\n",
       "[72385 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_small #preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup= pd.read_pickle('./pickles/books_look.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_small = make_smaller_lookup(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_small #preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup= pd.read_pickle('./pickles/videog_look.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_small = make_smaller_lookup(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_small #preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
