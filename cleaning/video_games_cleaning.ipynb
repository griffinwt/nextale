{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt\n",
    "#https://s3.amazonaws.com/amazon-reviews-pds/readme.html\n",
    "#https://www.tensorflow.org/datasets/catalog/amazon_us_reviews\n",
    "#https://stackoverflow.com/questions/39263929/how-can-i-read-tar-gz-file-using-pandas-read-csv-with-gzip-compression-option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('amazon_reviews_us_Video_Games_v1_00.tsv.gz', sep='\\t', compression='gzip', error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is somewhat out of order- I built up to creating the function and then moved it to the top so I could call it in on my video games data set without the need to run everything below it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "swords = set(stopwords.words('english')) #set nltk stopword list equal to a variable\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+') #create tokenizer to remove punctuation\n",
    "\n",
    "def tokem_lite(some_string):\n",
    "    stok = tokenizer.tokenize(some_string)\n",
    "    #stok = ' '.join(stok) #return string of words\n",
    "    slem = [lemmatizer.lemmatize(word) for word in stok]\n",
    "    #slem = lemmatizer.lemmatize(stok)\n",
    "    cleansw=[word for word in slem if word not in swords]\n",
    "    return ' '.join(cleansw)\n",
    "    for item in stok:\n",
    "        slems = []\n",
    "        for word in item:\n",
    "            slems.append(lemmatizer.lemmatize(word)) #make list of non-stop words\n",
    "            \n",
    "    return ' '.join(slems) #return string of words\n",
    "\n",
    "def clean_amazon_data(file_name, new_name):\n",
    "    df = pd.read_csv(file_name, sep='\\t', compression='gzip', error_bad_lines=False, low_memory=False) #read in file\n",
    "    df.drop(columns=['marketplace', 'vine', 'product_category'], inplace=True) #drop columns that won't be used\n",
    "    df['verified_purchase']=df['verified_purchase'].map({'Y':1, 'N':0}) #change verified_purchase to 1/0 classifier\n",
    "    df['review_date'] = pd.to_datetime(df['review_date']) #convert review date to date time object\n",
    "    print(f'Initial size: {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "    print(f'Initial shape: {df.shape}') #preview shape\n",
    "    \n",
    "    products = pd.Series(df['product_id'].value_counts()>10) #create bool series for whether item appears more than 10 times\n",
    "    prod_list = [] #create empty list\n",
    "    prod_dict = dict(products) #create dictionary of products series matching bool and product id\n",
    "    for key, value in prod_dict.items():\n",
    "        if value == False:\n",
    "            prod_list.append(key) #make a list of just product ids from series which appear less than 10 times\n",
    "    prod_in = df[df['product_id'].isin(prod_list)].index #make list of indexes of those product ids\n",
    "    df.drop(index=prod_in, inplace=True) #drop those indexes (all products with less than 10 reviews)\n",
    "    print(f'Size after dropping products w/reviews < 10: {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "    \n",
    "    print(f'Null Preview: {df.isnull().sum()}') #preview null values\n",
    "    null_perc = round((df.isnull().sum().sum()/len(df)*100),2)\n",
    "    print(f'Null Percentage: {null_perc}%') #% of null value rows out of all rows\n",
    "    dropped=False #null values have not been dropped\n",
    "    if null_perc < .1: #automatically drop nulls if they represent less than 1%\n",
    "        dropped=True\n",
    "        df.dropna(inplace=True)\n",
    "        print(f'Size after dropna(): {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "    else:  #if nulls are more than 1%, ask user to approve dropping\n",
    "        answer = input('Would you like to drop all null values? Please enter yes or no: ') #option to drop nulls\n",
    "        if answer.lower() == 'yes':\n",
    "            dropped=True\n",
    "            df.dropna(inplace=True)\n",
    "            print(f'Size after dropna(): {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "        else:\n",
    "            print('''\n",
    "            As you wish...\n",
    "            WARNING!\n",
    "            Null values remain in Data\n",
    "            ''')\n",
    "    \n",
    "    df['full_review'] = df['review_headline']+' '+df['review_body']#concatenate review header and body into one column for NLP\n",
    "    df.drop(columns=['review_headline', 'review_body'], inplace=True)\n",
    "    print(f'Size after concatenation: {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "    \n",
    "    if dropped == True: #only do this if nulls have been dropped, otherwise it will break\n",
    "        print('Tokenizing, lemmatizing, and removing stopwords...hold please')\n",
    "        df['full_review'] = df['full_review'].map(lambda x: tokem_lite(x)) #tokenize, lemmatize, and remove stopwords\n",
    "        print(f'Size after tokemmitization: {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "    \n",
    "    df.to_csv(f'./data/{new_name}.csv', index=False)\n",
    "    #print(f'File saved as {new_name}.csv')\n",
    "    \n",
    "    print(f'Final size: {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "    print(f'Final shape: {df.shape}') #preview shape\n",
    "    return f'File saved as {new_name}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'Null Percentage: {round((new_df.isnull().sum().sum()/len(new_df)*100),2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 20630: expected 15 fields, saw 22\\nSkipping line 28172: expected 15 fields, saw 22\\nSkipping line 54791: expected 15 fields, saw 22\\nSkipping line 75419: expected 15 fields, saw 22\\nSkipping line 104832: expected 15 fields, saw 22\\nSkipping line 138464: expected 15 fields, saw 22\\nSkipping line 194849: expected 15 fields, saw 22\\nSkipping line 201568: expected 15 fields, saw 22\\nSkipping line 242567: expected 15 fields, saw 22\\nSkipping line 493585: expected 15 fields, saw 22\\nSkipping line 502478: expected 15 fields, saw 22\\nSkipping line 660750: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial size: 1.718119368\n",
      "Initial shape: (1780268, 12)\n",
      "Size after dropping products w/reviews < 10: 1.616999617\n",
      "Null Preview: customer_id           0\n",
      "review_id             0\n",
      "product_id            0\n",
      "product_parent        0\n",
      "product_title         0\n",
      "star_rating           0\n",
      "helpful_votes         0\n",
      "total_votes           0\n",
      "verified_purchase     0\n",
      "review_headline      26\n",
      "review_body          51\n",
      "review_date          24\n",
      "dtype: int64\n",
      "Null Percentage: 0.01%\n",
      "Size after dropna(): 1.615822037\n",
      "Size after concatenation: 1.524033039\n",
      "Tokenizing, lemmatizing, and removing stopwords...hold please\n",
      "Size after tokemmitization: 1.181082599\n",
      "Final size: 1.181082599\n",
      "Final shape: (1648136, 11)\n",
      "Wall time: 10min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_df = clean_amazon_data('./data/amazon_reviews_us_Video_Games_v1_00.tsv.gz', 'video_games')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.265136394"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('./data/video_games.csv', low_memory=False) #preview saved csv file created by function\n",
    "sys.getsizeof(df2)/1_000_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       817185\n",
       "1       267812\n",
       "2       139116\n",
       "3        82764\n",
       "4        58745\n",
       "         ...  \n",
       "560          1\n",
       "563          1\n",
       "1174         1\n",
       "564          1\n",
       "1017         1\n",
       "Name: total_votes, Length: 714, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['total_votes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be an interesting project involving 'total votes', but it's not the project I'm working on. I think I can safely drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df['verified_purchase']=new_df['verified_purchase'].map({'Y':1, 'N':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.655297\n",
       "0    0.344703\n",
       "Name: verified_purchase, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_df['verified_purchase'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though I'm not planning to use verified_purchase in my project, it's possible I'll find a use for it and having it set up to work in a classification model makes sense, besides taking up less memory than strings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd like to have the option to perform NLP on the review text if I have time. It would be great to build in some tokenization, lemmitization, and stop word removal so that it's all ready for vectorization. It'll also make sense to combine review title and review text - not only to save a column and a little memory but also to be able to properly evaluate all the words the reviewer chose to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df['full_review'] = new_df['review_headline'] + ' ' + new_df['review_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df['full_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "swords = set(stopwords.words('english')) #set nltk stopword list equal to a variable\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+') #create tokenizer to remove punctuation\n",
    "\n",
    "def tokem_lite(some_string):\n",
    "    stok = tokenizer.tokenize(some_string)\n",
    "    #stok = ' '.join(stok) #return string of words\n",
    "    slem = [lemmatizer.lemmatize(word) for word in stok]\n",
    "    #slem = lemmatizer.lemmatize(stok)\n",
    "    cleansw=[word for word in slem if word not in swords]\n",
    "    return ' '.join(cleansw)\n",
    "    for item in stok:\n",
    "        slems = []\n",
    "        for word in item:\n",
    "            slems.append(lemmatizer.lemmatize(word)) #make list of non-stop words\n",
    "            \n",
    "    return ' '.join(slems) #return string of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amazing joystick I especially love twist Used Elite Dangerous mac amazing joystick I especially love twist stick different movement binding well move normal way'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokem_lite(new_df['full_review'][0]) #test on single row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             amazing joystick I especially love twist Used Elite Dangerous mac amazing joystick I especially love twist stick different movement binding well move normal way\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        One Star poor quality work advertised\n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              good could bettee nice tend slip away stick intense hard pressed gaming session\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Great flawed Great amiibo great collecting Quality material desired since perfect\n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                A Must I 2012 2013 XL durable comfortable really cool looking\n",
       "                                                                                                                                                                                                                                                                                                                                                          ...                                                                                                                                                                                                                                                                                                                                                 \n",
       "1780263                                                                       quot Riven quot generally life billing I think necessary wax poetic beautifully rendered graphic appears quot Riven quot Those seen Myst expect quot Riven quot disappoint The live action sequence especially haunting scene native relatively early game well done serve draw Riven even Myst It interesting see remarkable progression quality graphic quot Spelunx quot quot Myst quot quot Riven quot The puzzle quot Riven quot difficult quot Myst quot largely require move island reminiscent similar game quot The Dig quot However since puzzle built along principle quot Myst quot solved quot Myst quot able solve\n",
       "1780264    An Immersive Experience A Work Art If I could rate higher ten I would This truly I believe computer gaming like integration beautiful hand drawn artwork immerses completely self paced surreal world world Riven br These graphic The good people Cyan game designer accomplished artist The box say 100mhz 4x cd rom required artwork involved every scene intricate read realistic patience speed I played work instead lunch 100mhz 8x cd I wa waiting time scene appear Certainly say still worth home 200 machine flow wa instantaneous br Lots game computer involve killing I like personal reason Other game involve thinking one I play This best game I ever interacted true masterpiece\n",
       "1780265                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Riven Driven Microsoft Fewer 1 3 modern Windows computer running Windows 95 How rest u inclined pushed another operating system It bad But I buying copy one even though I thoroughly enjoyed Myst\n",
       "1780266                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Disappointment Unfortunately Riven available privilidged newest fastest hardware market Maybe future release sensitive le wealthy privilidged I disappointed\n",
       "1780267                                                                                                                                                                                    Engulfed Wonder If brave enough buy game following buy answering machine cancel appointment call sick lock door warm tea coffee install game hang Riven wonder surround matter second The detail music story keep breathless But doubt puzzle challenging If becomes frustrating relax point click everything look around There always another puzzle solve besides one No screen call answer door Just get freshen coffee grab quick snack Enjoy game ask people hint game precious solve quickly run museum would\n",
       "Name: full_review, Length: 1648136, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_df['full_review'].map(lambda x: tokem_lite(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df['revs_clean'] = [tokem_lite(review) for review in new_df['full_review']] #test on all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             amazing joystick I especially love twist Used Elite Dangerous mac amazing joystick I especially love twist stick different movement binding well move normal way\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        One Star poor quality work advertised\n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              good could bettee nice tend slip away stick intense hard pressed gaming session\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Great flawed Great amiibo great collecting Quality material desired since perfect\n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                A Must I 2012 2013 XL durable comfortable really cool looking\n",
       "                                                                                                                                                                                                                                                                                                                                                          ...                                                                                                                                                                                                                                                                                                                                                 \n",
       "1780263                                                                       quot Riven quot generally life billing I think necessary wax poetic beautifully rendered graphic appears quot Riven quot Those seen Myst expect quot Riven quot disappoint The live action sequence especially haunting scene native relatively early game well done serve draw Riven even Myst It interesting see remarkable progression quality graphic quot Spelunx quot quot Myst quot quot Riven quot The puzzle quot Riven quot difficult quot Myst quot largely require move island reminiscent similar game quot The Dig quot However since puzzle built along principle quot Myst quot solved quot Myst quot able solve\n",
       "1780264    An Immersive Experience A Work Art If I could rate higher ten I would This truly I believe computer gaming like integration beautiful hand drawn artwork immerses completely self paced surreal world world Riven br These graphic The good people Cyan game designer accomplished artist The box say 100mhz 4x cd rom required artwork involved every scene intricate read realistic patience speed I played work instead lunch 100mhz 8x cd I wa waiting time scene appear Certainly say still worth home 200 machine flow wa instantaneous br Lots game computer involve killing I like personal reason Other game involve thinking one I play This best game I ever interacted true masterpiece\n",
       "1780265                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Riven Driven Microsoft Fewer 1 3 modern Windows computer running Windows 95 How rest u inclined pushed another operating system It bad But I buying copy one even though I thoroughly enjoyed Myst\n",
       "1780266                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Disappointment Unfortunately Riven available privilidged newest fastest hardware market Maybe future release sensitive le wealthy privilidged I disappointed\n",
       "1780267                                                                                                                                                                                    Engulfed Wonder If brave enough buy game following buy answering machine cancel appointment call sick lock door warm tea coffee install game hang Riven wonder surround matter second The detail music story keep breathless But doubt puzzle challenging If becomes frustrating relax point click everything look around There always another puzzle solve besides one No screen call answer door Just get freshen coffee grab quick snack Enjoy game ask people hint game precious solve quickly run museum would\n",
       "Name: revs_clean, Length: 1648136, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_df['revs_clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2255759359"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['marketplace', 'customer_id', 'review_id', 'product_id',\n",
       "       'product_parent', 'product_title', 'product_category', 'star_rating',\n",
       "       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
       "       'review_headline', 'review_body', 'review_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace           0\n",
       "customer_id           0\n",
       "review_id             0\n",
       "product_id            0\n",
       "product_parent        0\n",
       "product_title         0\n",
       "product_category      0\n",
       "star_rating           0\n",
       "helpful_votes         0\n",
       "total_votes           0\n",
       "vine                  0\n",
       "verified_purchase     0\n",
       "review_headline      28\n",
       "review_body          59\n",
       "review_date          27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to build in a filter to drop any products with less than 10 reviews. That seems like a pretty low bar, and I want to be sure I have at least enough ratings for each item to make the recommender accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.Series(df['product_id'].value_counts()>10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df[products]==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B00Q538I46', 'B00N1O2A1Y', 'B00HNWZE18', 'B00JPI9YH8', 'B00004SVVU']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_list = []\n",
    "prod_dict = dict(products)\n",
    "for key, value in prod_dict.items():\n",
    "    if value == False:\n",
    "        prod_list.append(key)\n",
    "prod_list[:5] #preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_in = df[df['product_id'].isin(prod_list)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=prod_in, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B00BGA9WK2    10318\n",
       "B007FTE2VW     3971\n",
       "B00178630A     3715\n",
       "B0050SYILE     3545\n",
       "B005CPGHAA     3399\n",
       "              ...  \n",
       "B00002SWA8       11\n",
       "B0009350BC       11\n",
       "B000O3EFRM       11\n",
       "B0002SMN1Y       11\n",
       "B0007W65FA       11\n",
       "Name: product_id, Length: 20952, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['product_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['marketplace', 'customer_id', 'review_id', 'product_id',\n",
       "       'product_parent', 'product_title', 'product_category', 'star_rating',\n",
       "       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
       "       'review_headline', 'review_body', 'review_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "swords = set(stopwords.words('english')) #set nltk stopword list equal to a variable\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+') #create tokenizer to remove punctuation\n",
    "\n",
    "def tokem_lite(some_string):\n",
    "    stok = tokenizer.tokenize(some_string)\n",
    "    #stok = ' '.join(stok) #return string of words\n",
    "    slem = [lemmatizer.lemmatize(word) for word in stok]\n",
    "    #slem = lemmatizer.lemmatize(stok)\n",
    "    cleansw=[word for word in slem if word not in swords]\n",
    "    return ' '.join(cleansw)\n",
    "    for item in stok:\n",
    "        slems = []\n",
    "        for word in item:\n",
    "            slems.append(lemmatizer.lemmatize(word)) #make list of non-stop words\n",
    "            \n",
    "    return ' '.join(slems) #return string of words\n",
    "\n",
    "def clean_amazon_data(file_name, new_name):\n",
    "    df = pd.read_csv(file_name, sep='\\t', compression='gzip', error_bad_lines=False, low_memory=False) #read in file\n",
    "    df.drop(columns=['marketplace', 'vine', 'product_category'], inplace=True) #drop columns that won't be used\n",
    "    df['verified_purchase']=df['verified_purchase'].map({'Y':1, 'N':0}) #change verified_purchase to 1/0 classifier\n",
    "    df['review_date'] = pd.to_datetime(df['review_date']) #convert review date to date time object\n",
    "    print(f'Initial size: {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "    print(f'Initial shape: {df.shape}') #preview shape\n",
    "    \n",
    "    products = pd.Series(df['product_id'].value_counts()>10) #create bool series for whether item appears more than 10 times\n",
    "    prod_list = [] #create empty list\n",
    "    prod_dict = dict(products) #create dictionary of products series matching bool and product id\n",
    "    for key, value in prod_dict.items():\n",
    "        if value == False:\n",
    "            prod_list.append(key) #make a list of just product ids from series which appear less than 10 times\n",
    "    prod_in = df[df['product_id'].isin(prod_list)].index #make list of indexes of those product ids\n",
    "    df.drop(index=prod_in, inplace=True) #drop those indexes (all products with less than 10 reviews)\n",
    "    print(f'Size after dropping products w/reviews < 10: {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "    \n",
    "    print(f'Null Preview: {df.isnull().sum()}') #preview null values\n",
    "    null_perc = round((df.isnull().sum().sum()/len(df)*100),2)\n",
    "    print(f'Null Percentage: {null_perc}%') #% of null value rows out of all rows\n",
    "    dropped=False #null values have not been dropped\n",
    "    if null_perc < .1: #automatically drop nulls if they represent less than 1%\n",
    "        dropped=True\n",
    "        df.dropna(inplace=True)\n",
    "        print(f'Size after dropna(): {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "    else:  #if nulls are more than 1%, ask user to approve dropping\n",
    "        answer = input('Would you like to drop all null values? Please enter yes or no: ') #option to drop nulls\n",
    "        if answer.lower() == 'yes':\n",
    "            dropped=True\n",
    "            df.dropna(inplace=True)\n",
    "            print(f'Size after dropna(): {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "        else:\n",
    "            print('''\n",
    "            As you wish...\n",
    "            WARNING!\n",
    "            Null values remain in Data\n",
    "            ''')\n",
    "    \n",
    "    df['full_review'] = df['review_headline']+' '+df['review_body']#concatenate review header and body into one column for NLP\n",
    "    df.drop(columns=['review_headline', 'review_body'], inplace=True)\n",
    "    print(f'Size after concatenation: {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "    \n",
    "    if dropped == True: #only do this if nulls have been dropped, otherwise it will break\n",
    "        print('Tokenizing, lemmatizing, and removing stopwords...hold please')\n",
    "        df['full_review'] = df['full_review'].map(lambda x: tokem_lite(x)) #tokenize, lemmatize, and remove stopwords\n",
    "        print(f'Size after tokemmitization: {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "    \n",
    "    df.to_csv(f'./data/{new_name}.csv', index=False)\n",
    "    #print(f'File saved as {new_name}.csv')\n",
    "    \n",
    "    print(f'Final size: {sys.getsizeof(df)/1_000_000_000}') # print size of file (in Gigs)\n",
    "    print(f'Final shape: {df.shape}') #preview shape\n",
    "    return f'File saved as {new_name}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go - my cleaning function is saved in the utilities python file and ready for use on the (larger) movies and video games files!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
